{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 3 - NER",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WJBimYDLJS"
      },
      "source": [
        "# Assignment 3\n",
        "Training a neural named entity recognition (NER) tagger "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3enPCGBF8FlX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3fc06bd5-afdc-4dc6-c416-80c7e7c8440b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# additinal packages\n",
        "import os,io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from random import shuffle\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "# Disabling autoscrolling for long output\n",
        "# %%javascript\n",
        "# IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
        "#     return false;\n",
        "# }\n",
        "\n",
        "\n",
        "from google.colab import drive  \n",
        "drive.mount(r'/content/drive/',force_remount=True) \n",
        "\n",
        "data_dir = os.getcwd() + '/' + 'drive/My Drive/Colab Notebooks/NLP/HW3'\n",
        "data_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/NLP/HW3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5QSIEoyDdWh"
      },
      "source": [
        "In this assignment you are required to build a full training and testing pipeline for a neural sequentail tagger for named entities, using LSTM.\n",
        "\n",
        "The dataset that you will be working on is called ReCoNLL 2003, which is a corrected version of the CoNLL 2003 dataset: https://www.clips.uantwerpen.be/conll2003/ner/\n",
        "\n",
        "[Train data](https://drive.google.com/file/d/1hG66e_OoezzeVKho1w7ysyAx4yp0ShDz/view?usp=sharing)\n",
        "\n",
        "[Dev data](https://drive.google.com/file/d/1EAF-VygYowU1XknZhvzMi2CID65I127L/view?usp=sharing)\n",
        "\n",
        "[Test data](https://drive.google.com/file/d/16gug5wWnf06JdcBXQbcICOZGZypgr4Iu/view?usp=sharing)\n",
        "\n",
        "As you can see, the annotated texts are labeled according to the IOB annotation scheme, for 3 entity types: Person, Organization, Location."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ul2Y3vuPoV8"
      },
      "source": [
        "**Task 1:** Write a funtion for reading the data from a single file (of the ones that are provided above). The function recieves a filepath and then it encodes every sentence individually using a pair of lists, one list contains the words and one list contains the tags. Each list pair will be added to a general list (data), which will be returned back from the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prgzgtt8Jw4Y"
      },
      "source": [
        "def read_data(filepath):\n",
        "    data = []\n",
        "    # TODO... write your code accordingly \n",
        "    \n",
        "    # read file - split into lines\n",
        "    with open(data_dir + '/' + filepath,'r') as f:\n",
        "        output = f.read().splitlines()\n",
        "\n",
        "    # initial new sentence\n",
        "    words = []\n",
        "    tags  = []\n",
        "    \n",
        "    # run on all lines and create sentences based on this way --> data[i] = list(words):list(tags)\n",
        "    for o in output:\n",
        "        \n",
        "        # for every new sentence\n",
        "        if o=='':\n",
        "            data.append((words,tags))\n",
        "            tags=[]\n",
        "            words=[]\n",
        "            continue\n",
        "\n",
        "        # for each line split into word:tag\n",
        "        w,t = o.strip().split(' ') # did not lower case\n",
        "        words.append(w)\n",
        "        tags.append(t)\n",
        "\n",
        "    # when files end, add last sentence (if it's not empty)\n",
        "    if len(words):\n",
        "        data.append((words,tags))\n",
        "\n",
        "    return data\n",
        "\n",
        "# # Google Drive\n",
        "# train = read_data('https://drive.google.com/file/d/1hG66e_OoezzeVKho1w7ysyAx4yp0ShDz/view?usp=sharing')\n",
        "# dev = read_data('https://drive.google.com/file/d/1EAF-VygYowU1XknZhvzMi2CID65I127L/view?usp=sharing')\n",
        "# test = read_data('https://drive.google.com/file/d/16gug5wWnf06JdcBXQbcICOZGZypgr4Iu/view?usp=sharing')\n",
        "\n",
        "train,dev,test = read_data('data/connl03_train.txt'), read_data('data/connl03_dev.txt'), read_data('data/connl03_test.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGwk6OwRWGS"
      },
      "source": [
        "The following Vocab class can be served as a dictionary that maps words and tags into Ids. The UNK_TOKEN should be used for words that are not part of the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rKIB5o_vQO8"
      },
      "source": [
        "UNK_TOKEN = 0\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self):\n",
        "        self.word2id = {\"__unk__\": UNK_TOKEN}\n",
        "        self.id2word = {UNK_TOKEN: \"__unk__\"}\n",
        "        self.n_words = 1\n",
        "        \n",
        "        self.tag2id = {\"O\":0, \"B-PER\":1, \"I-PER\": 2, \"B-LOC\": 3, \"I-LOC\": 4, \"B-ORG\": 5, \"I-ORG\": 6}\n",
        "        self.id2tag = {0:\"O\", 1:\"B-PER\", 2:\"I-PER\", 3:\"B-LOC\", 4:\"I-LOC\", 5:\"B-ORG\", 6:\"I-ORG\"}\n",
        "        \n",
        "    def index_words(self, words):\n",
        "      word_indexes = [self.index_word(w) for w in words]\n",
        "      return word_indexes\n",
        "\n",
        "    def index_tags(self, tags):\n",
        "      tag_indexes = [self.tag2id[t] for t in tags]\n",
        "      return tag_indexes\n",
        "    \n",
        "    def index_word(self, w):\n",
        "        if w not in self.word2id:\n",
        "            self.word2id[w] = self.n_words\n",
        "            self.id2word[self.n_words] = w\n",
        "            self.n_words += 1\n",
        "        return self.word2id[w]\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDKYryfKfNdh"
      },
      "source": [
        "**Task 2:** Write a function prepare_data that takes one of the [train, dev, test] and the Vocab instance, for converting each pair of (words,tags) to a pair of indexes. Each pair should be added to data_sequences, which will be returned back from the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noIY3zWKvhBd"
      },
      "source": [
        "vocab = Vocab()\n",
        "\n",
        "def prepare_data(data, vocab):\n",
        "    data_sequences = []\n",
        "    # TODO - your code...\n",
        "    \n",
        "    # iterate on data\n",
        "    for words,tags in data:\n",
        "        \n",
        "        # from string to index\n",
        "        words_indexes = vocab.index_words(words)\n",
        "        tags_indexes = vocab.index_tags(tags)\n",
        "        \n",
        "        # from index to tensor & upload on DEVICE\n",
        "        words_indexes_tensor = torch.tensor(words_indexes,dtype=torch.long).to(DEVICE) \n",
        "        tags_indexes_tensor = torch.tensor(tags_indexes,dtype=torch.long).to(DEVICE)\n",
        "        \n",
        "        data_sequences.append((words_indexes_tensor,tags_indexes_tensor))\n",
        "        \n",
        "    return data_sequences, vocab\n",
        "\n",
        "train_sequences, vocab = prepare_data(train, vocab)\n",
        "dev_sequences, vocab = prepare_data(dev, vocab)\n",
        "test_sequences, vocab = prepare_data(test, vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UccfiRRtiEet"
      },
      "source": [
        "**Task 3:** Write NERNet, a PyTorch Module for labeling words with NER tags. \n",
        "\n",
        "*input_size:* the size of the vocabulary\n",
        "\n",
        "*embedding_size:* the size of the embeddings\n",
        "\n",
        "*hidden_size:* the LSTM hidden size\n",
        "\n",
        "*output_size:* the number tags we are predicting for\n",
        "\n",
        "*n_layers:* the number of layers we want to use in LSTM\n",
        "\n",
        "*directions:* could 1 or 2, indicating unidirectional or bidirectional LSTM, respectively\n",
        "\n",
        "The input for your forward function should be a single sentence tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke1LyUQNyQaM"
      },
      "source": [
        "class NERNet(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, n_layers, directions):\n",
        "        super(NERNet, self).__init__()\n",
        "        # TODO: your code...\n",
        "        \n",
        "        # Embeddings -> LSTM -> Linear -> Cross Entropy\n",
        "        \n",
        "        self.input_size      = input_size\n",
        "        self.output_size     = output_size\n",
        "        self.embedding_size  = embedding_size\n",
        "        self.hidden_size     = hidden_size\n",
        "        self.n_layers        = n_layers\n",
        "        self.directions      = directions\n",
        "        \n",
        "        # bidirectional if directions==2 else 1\n",
        "        self.isTwoDirections = (directions==2)\n",
        "                \n",
        "        # Embbeding Layer\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        \n",
        "        # LSTM Layyer\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, bidirectional=self.isTwoDirections)\n",
        "        \n",
        "        # Linear Layer\n",
        "        self.out = nn.Linear(hidden_size*directions, output_size) # if bidirectional then multiply the hidden size\n",
        "    \n",
        "    \n",
        "    def forward(self, input_sentence):\n",
        "        # TODO: your code...\n",
        "        \n",
        "        dim = len(input_sentence)\n",
        "        sentence = input_sentence.clone().detach().to(DEVICE)\n",
        "        # print(dim)                           # for debbuging\n",
        "\n",
        "        embeds = self.embedding(sentence)\n",
        "        # print(embeds.shape)                  # for debbuging\n",
        "        \n",
        "        lstm_out, _ = self.lstm(embeds.view(dim, 1, -1))\n",
        "        # print(lstm_out.shape)                # for debbuging\n",
        "        \n",
        "        output = self.out(lstm_out.view(dim, -1))\n",
        "        # print(output.shape)                  # for debbuging\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEGSQdeUkTP8"
      },
      "source": [
        "**Task 4:** write a training loop, which takes a model (instance of NERNet) and number of epochs to train on. The loss is always CrossEntropyLoss and the optimizer is always Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avkHfjT3k0HM"
      },
      "source": [
        "def train_loop(model, n_epochs):\n",
        "  \n",
        "    # shupple the data\n",
        "    shuffle(train_sequences)\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizer (ADAM is a fancy version of SGD)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    \n",
        "    # did not ask to stop when converges to ϵ loss\n",
        "    for e in range(1, n_epochs + 1):\n",
        "        for sentence,tags in train_sequences:\n",
        "            model.zero_grad()\n",
        "            scores = model(sentence)\n",
        "            criterion(scores,tags).backward()\n",
        "            optimizer.step()\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baN1c_B7lTjb"
      },
      "source": [
        "**Task 5:** write an evaluation loop on a trained model, using the dev and test datasets. This function print the true positive rate (TPR), also known as Recall and the opposite to false positive rate (FPR), also known as precision, of each label seperately (7 labels in total), and for all the 6 labels (except O) together. The caption argument for the function should be served for printing, so that when you print include it as a prefix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyQAjGaqmd8U"
      },
      "source": [
        "def evaluate(model, caption=''):\n",
        "    # TODO - your code goes here\n",
        "    n_labels = len(vocab.tag2id)\n",
        "    dev_matrix = torch.zeros(n_labels,n_labels) \n",
        "    test_matrix = torch.zeros(n_labels,n_labels)\n",
        "    \n",
        "    # evaluate dev\n",
        "    with torch.no_grad():\n",
        "        for inputs,labels in dev_sequences:\n",
        "            preds = model(inputs).max(1).indices\n",
        "            for label,pred in zip(labels,preds):\n",
        "                dev_matrix[label,pred] += 1 \n",
        "    \n",
        "    # evaluate test\n",
        "    with torch.no_grad():\n",
        "        for inputs,labels in test_sequences:\n",
        "            preds = model(inputs).max(1).indices\n",
        "            for label,pred in zip(labels,preds):\n",
        "                test_matrix[label,pred] += 1 \n",
        "    \n",
        "    # Precision -- total_true_label = dev_matrix.sum(1) \n",
        "    dev_precision = dev_matrix.diag()/dev_matrix.sum(1)\n",
        "    test_precision = test_matrix.diag()/test_matrix.sum(1)\n",
        "    \n",
        "    # Recall -- total_pred_label = dev_matrix.sum(0)\n",
        "    dev_recall = dev_matrix.diag()/dev_matrix.sum(0)\n",
        "    test_recall = test_matrix.diag()/test_matrix.sum(0)\n",
        "    \n",
        "    # Construct a display table\n",
        "    df = pd.DataFrame(columns=vocab.tag2id.keys())\n",
        "    df.loc['dev  Precision'] = dev_precision.tolist()\n",
        "    df.loc['dev  Recall'] = dev_precision.tolist()\n",
        "    df.loc['test Precision'] = test_precision.tolist()\n",
        "    df.loc['test Recall'] = test_recall.tolist()\n",
        "\n",
        "    # add 6 labels to additional column\n",
        "    dev_precision_except_0 = dev_matrix[1:,1:].diag().sum()/dev_matrix[1:,1:].sum(1).sum()\n",
        "    test_precision_except_0 = test_matrix[1:,1:].diag().sum()/test_matrix[1:,1:].sum(1).sum()\n",
        "    dev_recall_except_0 = dev_matrix[1:,1:].diag().sum()/dev_matrix[1:,1:].sum(0).sum()\n",
        "    test_recall_except_0 = test_matrix[1:,1:].diag().sum()/test_matrix[1:,1:].sum(0).sum()\n",
        "    \n",
        "    df.loc['dev  Precision','All-Exapct-O'] = float(dev_precision_except_0)\n",
        "    df.loc['dev  Recall','All-Exapct-O']    = float(dev_recall_except_0)\n",
        "    df.loc['test Precision','All-Exapct-O'] = float(test_precision_except_0)\n",
        "    df.loc['test Recall','All-Exapct-O']    = float(test_recall_except_0)\n",
        "\n",
        "\n",
        "    # in case of dividing by zero\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    # BOLD without importing additional packages\n",
        "    print('\\x1b[1;11;11;11m'+ caption + '\\x1b[0m')\n",
        "    print(tabulate(df,headers='keys',tablefmt='psql'))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQSXqWNOmqG4"
      },
      "source": [
        "**Task 6:** Train and evaluate a few models, all with embedding_size=300, and with the following hyper parameters (you may use that as captions for the models as well):\n",
        "\n",
        "Model 1: (hidden_size: 500, n_layers: 1, directions: 1)\n",
        "\n",
        "Model 2: (hidden_size: 500, n_layers: 2, directions: 1)\n",
        "\n",
        "Model 3: (hidden_size: 500, n_layers: 3, directions: 1)\n",
        "\n",
        "Model 4: (hidden_size: 500, n_layers: 1, directions: 2)\n",
        "\n",
        "Model 5: (hidden_size: 500, n_layers: 2, directions: 2)\n",
        "\n",
        "Model 6: (hidden_size: 500, n_layers: 3, directions: 2)\n",
        "\n",
        "Model 4: (hidden_size: 800, n_layers: 1, directions: 2)\n",
        "\n",
        "Model 5: (hidden_size: 800, n_layers: 2, directions: 2)\n",
        "\n",
        "Model 6: (hidden_size: 800, n_layers: 3, directions: 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trnICYsTaXD6"
      },
      "source": [
        "**Get a dict with all pramam instructed above**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTNmBU6hycZl"
      },
      "source": [
        "def get_models_params():\n",
        "    models = {}\n",
        "\n",
        "    INPUT_SIZE = len(vocab.word2id)\n",
        "    OUTPUT_SIZE = len(vocab.tag2id)\n",
        "\n",
        "    embedding_sizes = [300]\n",
        "    hidden_sizes = [500,800]\n",
        "    n_layes = [1,2,3]\n",
        "    directions = [1,2]\n",
        "\n",
        "    # create all models params\n",
        "    for es in embedding_sizes:\n",
        "        for hs in hidden_sizes:\n",
        "            for l in n_layes:\n",
        "                for d in directions:\n",
        "                    models[len(models)+1] = {'input_size':INPUT_SIZE,'output_size':OUTPUT_SIZE,'embedding_size':es,'hidden_size': hs, 'n_layers': l, 'directions': d}\n",
        "    return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7acyu44tadPf"
      },
      "source": [
        "**Train & Eval models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cUE36tHadco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6428e1e-3a80-4f09-eb67-b2f7d802bad5"
      },
      "source": [
        "EPOCHS = 10\n",
        "MULTIPLE_CUDA = torch.cuda.device_count()>1 \n",
        "\n",
        "models = get_models_params()\n",
        "\n",
        "for k in models:\n",
        "    model = NERNet(**models[k])\n",
        "    model.cuda()\n",
        "    \n",
        "    if MULTIPLE_CUDA:\n",
        "        model = nn.DataParallel(model) \n",
        "\n",
        "    train_loop(model,n_epochs=EPOCHS)\n",
        "    caption = 'Model {0}: (hidden_size: {1}, n_layers: {2}, directions: {3})'.format(k,model.hidden_size,model.n_layers,model.directions)\n",
        "    evaluate(model,caption)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;11;11;11mModel 1: (hidden_size: 500, n_layers: 1, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.977067 | 0.605    | 0.630573 | 0.666667 | 0.391304 | 0.565476 | 0.37069  |       0.862434 |\n",
            "| dev  Recall    | 0.977067 | 0.605    | 0.630573 | 0.666667 | 0.391304 | 0.565476 | 0.37069  |       0.862434 |\n",
            "| test Precision | 0.97457  | 0.573733 | 0.621622 | 0.670554 | 0.509434 | 0.534286 | 0.325    |       0.860274 |\n",
            "| test Recall    | 0.916774 | 0.821782 | 0.867925 | 0.809859 | 1        | 0.58805  | 0.550847 |       0.860274 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 2: (hidden_size: 500, n_layers: 1, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.969315 | 0.77     | 0.636943 | 0.726776 | 0.391304 | 0.565476 | 0.474138 |       0.863924 |\n",
            "| dev  Recall    | 0.969315 | 0.77     | 0.636943 | 0.726776 | 0.391304 | 0.565476 | 0.474138 |       0.863924 |\n",
            "| test Precision | 0.965281 | 0.760369 | 0.611486 | 0.696793 | 0.54717  | 0.591429 | 0.4      |       0.863857 |\n",
            "| test Recall    | 0.934818 | 0.611111 | 0.900497 | 0.824138 | 0.966667 | 0.739286 | 0.661157 |       0.863857 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 3: (hidden_size: 500, n_layers: 2, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.959948 | 0.675    | 0.675159 | 0.770492 | 0.478261 | 0.595238 | 0.37069  |       0.872964 |\n",
            "| dev  Recall    | 0.959948 | 0.675    | 0.675159 | 0.770492 | 0.478261 | 0.595238 | 0.37069  |       0.872964 |\n",
            "| test Precision | 0.963606 | 0.691244 | 0.709459 | 0.723032 | 0.603774 | 0.614286 | 0.4      |       0.843046 |\n",
            "| test Recall    | 0.942087 | 0.74813  | 0.786517 | 0.765432 | 0.864865 | 0.612536 | 0.547945 |       0.843046 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 4: (hidden_size: 500, n_layers: 2, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.984819 | 0.765    | 0.764331 | 0.704918 | 0.478261 | 0.60119  | 0.482759 |       0.901899 |\n",
            "| dev  Recall    | 0.984819 | 0.765    | 0.764331 | 0.704918 | 0.478261 | 0.60119  | 0.482759 |       0.901899 |\n",
            "| test Precision | 0.978072 | 0.769585 | 0.753378 | 0.685131 | 0.603774 | 0.537143 | 0.465    |       0.902041 |\n",
            "| test Recall    | 0.93439  | 0.762557 | 0.785211 | 0.896947 | 0.914286 | 0.854545 | 0.715385 |       0.902041 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 5: (hidden_size: 500, n_layers: 3, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.973514 | 0.665    | 0.675159 | 0.672131 | 0.478261 | 0.60119  | 0.405172 |       0.859736 |\n",
            "| dev  Recall    | 0.973514 | 0.665    | 0.675159 | 0.672131 | 0.478261 | 0.60119  | 0.405172 |       0.859736 |\n",
            "| test Precision | 0.966499 | 0.638249 | 0.675676 | 0.661808 | 0.509434 | 0.591429 | 0.355    |       0.854361 |\n",
            "| test Recall    | 0.927653 | 0.767313 | 0.83682  | 0.825455 | 0.818182 | 0.579832 | 0.522059 |       0.854361 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 6: (hidden_size: 500, n_layers: 3, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.935401 | 0.65     | 0.707006 | 0.857924 | 0.652174 | 0.672619 | 0.594828 |       0.82296  |\n",
            "| dev  Recall    | 0.935401 | 0.65     | 0.707006 | 0.857924 | 0.652174 | 0.672619 | 0.594828 |       0.82296  |\n",
            "| test Precision | 0.936501 | 0.656682 | 0.712838 | 0.874636 | 0.811321 | 0.72     | 0.65     |       0.831178 |\n",
            "| test Recall    | 0.967437 | 0.874233 | 0.875519 | 0.576923 | 0.511905 | 0.59434  | 0.446735 |       0.831178 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 7: (hidden_size: 800, n_layers: 1, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.961886 | 0.65     | 0.66879  | 0.737705 | 0.434783 | 0.52381  | 0.362069 |       0.877797 |\n",
            "| dev  Recall    | 0.961886 | 0.65     | 0.66879  | 0.737705 | 0.434783 | 0.52381  | 0.362069 |       0.877797 |\n",
            "| test Precision | 0.964215 | 0.654378 | 0.655405 | 0.77551  | 0.641509 | 0.528571 | 0.345    |       0.870152 |\n",
            "| test Recall    | 0.928174 | 0.741514 | 0.804979 | 0.730769 | 0.944444 | 0.646853 | 0.621622 |       0.870152 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 8: (hidden_size: 800, n_layers: 1, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.976421 | 0.675    | 0.687898 | 0.715847 | 0.347826 | 0.595238 | 0.344828 |        0.85155 |\n",
            "| dev  Recall    | 0.976421 | 0.675    | 0.687898 | 0.715847 | 0.347826 | 0.595238 | 0.344828 |        0.85155 |\n",
            "| test Precision | 0.97792  | 0.686636 | 0.692568 | 0.737609 | 0.584906 | 0.634286 | 0.34     |        0.90201 |\n",
            "| test Recall    | 0.930185 | 0.807588 | 0.850622 | 0.813505 | 0.911765 | 0.732673 | 0.839506 |        0.90201 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 9: (hidden_size: 800, n_layers: 2, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.972868 | 0.665    | 0.738854 | 0.699454 | 0.391304 | 0.559524 | 0.405172 |       0.851373 |\n",
            "| dev  Recall    | 0.972868 | 0.665    | 0.738854 | 0.699454 | 0.391304 | 0.559524 | 0.405172 |       0.851373 |\n",
            "| test Precision | 0.961931 | 0.672811 | 0.719595 | 0.688047 | 0.471698 | 0.554286 | 0.385    |       0.844463 |\n",
            "| test Recall    | 0.933777 | 0.666667 | 0.747368 | 0.816609 | 0.862069 | 0.648829 | 0.557971 |       0.844463 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 10: (hidden_size: 800, n_layers: 2, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.965116 | 0.795    | 0.808917 | 0.743169 | 0.478261 | 0.64881  | 0.474138 |       0.865217 |\n",
            "| dev  Recall    | 0.965116 | 0.795    | 0.808917 | 0.743169 | 0.478261 | 0.64881  | 0.474138 |       0.865217 |\n",
            "| test Precision | 0.964063 | 0.785714 | 0.810811 | 0.772595 | 0.622642 | 0.654286 | 0.465    |       0.888971 |\n",
            "| test Recall    | 0.951172 | 0.736501 | 0.776699 | 0.84127  | 0.942857 | 0.685629 | 0.709924 |       0.888971 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 11: (hidden_size: 800, n_layers: 3, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.97416  | 0.65     | 0.66242  | 0.73224  | 0.608696 | 0.559524 | 0.465517 |        0.85622 |\n",
            "| dev  Recall    | 0.97416  | 0.65     | 0.66242  | 0.73224  | 0.608696 | 0.559524 | 0.465517 |        0.85622 |\n",
            "| test Precision | 0.967717 | 0.631336 | 0.699324 | 0.740525 | 0.641509 | 0.594286 | 0.445    |        0.86246 |\n",
            "| test Recall    | 0.935247 | 0.771831 | 0.8625   | 0.78882  | 0.73913  | 0.619048 | 0.597315 |        0.86246 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 12: (hidden_size: 800, n_layers: 3, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.978036 | 0.73     | 0.815287 | 0.765027 | 0.434783 | 0.613095 | 0.448276 |       0.893519 |\n",
            "| dev  Recall    | 0.978036 | 0.73     | 0.815287 | 0.765027 | 0.434783 | 0.613095 | 0.448276 |       0.893519 |\n",
            "| test Precision | 0.972742 | 0.730415 | 0.783784 | 0.793003 | 0.641509 | 0.625714 | 0.43     |       0.892308 |\n",
            "| test Recall    | 0.944412 | 0.804569 | 0.77592  | 0.842105 | 0.772727 | 0.755172 | 0.666667 |       0.892308 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM74r0_8nk5s"
      },
      "source": [
        "**Task 6:** Download the GloVe embeddings from https://nlp.stanford.edu/projects/glove/ (use the 300-dim vectors from glove.6B.zip). Then intialize the nn.Embedding module in your NERNet with these embeddings, so that you can start your training with pre-trained vectors. Repeat Task 6 and print the results for each model.\n",
        "\n",
        "Note: make sure that vectors are aligned with the IDs in your Vocab, in other words, make sure that for example the word with ID 0 is the first vector in the GloVe matrix of vectors that you initialize nn.Embedding with. For a dicussion on how to do that, check it this link:\n",
        "https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRIkLN3cawDd"
      },
      "source": [
        "**Get Glove Pretrained Embeddings Weights on google colab**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4NkThHpcXxd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "ceb5f3c3-20f9-45a2-be59-42f84cf20931"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-27 12:16:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-06-27 12:16:39--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-06-27 12:16:39--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.96MB/s    in 6m 29s  \n",
            "\n",
            "2020-06-27 12:23:09 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zDbAb_DeSkP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "624b6400-b40a-4fc1-a344-86866d6d99ee"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  glove.6B.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyrYEtnodPOD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "acab5c3a-fd1a-4194-f2f3-d174fd989c30"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uelWb2ocex3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "38dec35c-fa3a-484c-c19d-9f62936acff2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   glove.6B.200d.txt  glove.6B.50d.txt\tsample_data\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC7u7Q7ndsUa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a607cb51-a76f-4ea8-de73-334f8bf00a5d"
      },
      "source": [
        "!rm glove.6B.200d.txt\n",
        "!rm glove.6B.50d.txt\n",
        "!rm glove.6B.100d.txt\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  glove.6B.300d.txt  glove.6B.zip\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5dqRuCOfYcb"
      },
      "source": [
        "GLOVE_PATH = 'glove.6B.300d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG9e9NJmjSRw"
      },
      "source": [
        "**Helper Function**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6CEvtPKawVC"
      },
      "source": [
        "def load_glove_embeddings(path, word2idx=vocab.word2id, embedding_dim=300):\n",
        "    with open(path,encoding='utf-8') as f:\n",
        "        embeddings = np.zeros((len(word2idx), embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb1J8sT8a5uv"
      },
      "source": [
        "**Train & Eval**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRiMbvx9o5Rh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f53c1c8b-b40a-41c0-f76a-07f5f7788014"
      },
      "source": [
        "EPOCHS = 10\n",
        "MULTIPLE_CUDA = torch.cuda.device_count()>1 \n",
        "\n",
        "models = get_models_params()\n",
        "\n",
        "for k in models:\n",
        "    model = NERNet(**models[k])\n",
        "\n",
        "    # load pretrained weights & freeze them (.grad=false)\n",
        "    weights = load_glove_embeddings(GLOVE_PATH)\n",
        "    model.embedding = nn.Embedding.from_pretrained(weights,freeze=True)\n",
        "\n",
        "    model.cuda()\n",
        "    \n",
        "    if MULTIPLE_CUDA:\n",
        "        model = nn.DataParallel(model) \n",
        "\n",
        "    train_loop(model,n_epochs=EPOCHS)\n",
        "    caption = 'Model {0}: (hidden_size: {1}, n_layers: {2}, directions: {3})'.format(k,model.hidden_size,model.n_layers,model.directions)\n",
        "    evaluate(model,caption)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;11;11;11mModel 1: (hidden_size: 500, n_layers: 1, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.952196 | 0.545    | 0.821656 | 0.644809 | 0.434783 | 0.607143 | 0.37069  |       0.750367 |\n",
            "| dev  Recall    | 0.952196 | 0.545    | 0.821656 | 0.644809 | 0.434783 | 0.607143 | 0.37069  |       0.750367 |\n",
            "| test Precision | 0.95249  | 0.479263 | 0.810811 | 0.620991 | 0.471698 | 0.648571 | 0.375    |       0.721168 |\n",
            "| test Recall    | 0.953361 | 0.809339 | 0.574163 | 0.67619  | 0.543478 | 0.426692 | 0.657895 |       0.721168 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 2: (hidden_size: 500, n_layers: 1, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.978036 | 0.765    | 0.878981 | 0.617486 | 0.347826 | 0.547619 | 0.405172 |       0.821162 |\n",
            "| dev  Recall    | 0.978036 | 0.765    | 0.878981 | 0.617486 | 0.347826 | 0.547619 | 0.405172 |       0.821162 |\n",
            "| test Precision | 0.973047 | 0.718894 | 0.858108 | 0.61516  | 0.320755 | 0.608571 | 0.445    |       0.853583 |\n",
            "| test Recall    | 0.9422   | 0.739336 | 0.801262 | 0.796226 | 0.62963  | 0.693811 | 0.723577 |       0.853583 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 3: (hidden_size: 500, n_layers: 2, directions: 1)\u001b[0m\n",
            "+----------------+----------+---------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |   B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+---------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.941214 |   0.535 | 0.796178 | 0.666667 | 0.347826 | 0.678571 | 0.448276 |       0.718367 |\n",
            "| dev  Recall    | 0.941214 |   0.535 | 0.796178 | 0.666667 | 0.347826 | 0.678571 | 0.448276 |       0.718367 |\n",
            "| test Precision | 0.943049 |   0.5   | 0.773649 | 0.658892 | 0.490566 | 0.682857 | 0.425    |       0.704828 |\n",
            "| test Recall    | 0.964792 |   0.775 | 0.582697 | 0.617486 | 0.577778 | 0.422261 | 0.488506 |       0.704828 |\n",
            "+----------------+----------+---------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 4: (hidden_size: 500, n_layers: 2, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.967054 | 0.8      | 0.910828 | 0.661202 | 0.391304 | 0.678571 | 0.681035 |       0.821522 |\n",
            "| dev  Recall    | 0.967054 | 0.8      | 0.910828 | 0.661202 | 0.391304 | 0.678571 | 0.681035 |       0.821522 |\n",
            "| test Precision | 0.967108 | 0.721198 | 0.878378 | 0.6793   | 0.54717  | 0.748571 | 0.69     |       0.840136 |\n",
            "| test Recall    | 0.968583 | 0.823684 | 0.846906 | 0.820423 | 0.805556 | 0.59009  | 0.587234 |       0.840136 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 5: (hidden_size: 500, n_layers: 3, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.942506 | 0.475    | 0.770701 | 0.52459  | 0.347826 | 0.791667 | 0.577586 |       0.674449 |\n",
            "| dev  Recall    | 0.942506 | 0.475    | 0.770701 | 0.52459  | 0.347826 | 0.791667 | 0.577586 |       0.674449 |\n",
            "| test Precision | 0.94046  | 0.435484 | 0.787162 | 0.527697 | 0.377358 | 0.785714 | 0.525    |       0.659435 |\n",
            "| test Recall    | 0.975517 | 0.836283 | 0.585427 | 0.790393 | 0.425532 | 0.351662 | 0.456522 |       0.659435 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 6: (hidden_size: 500, n_layers: 3, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.965762 | 0.82     | 0.872611 | 0.759563 | 0.478261 | 0.607143 | 0.646552 |       0.828496 |\n",
            "| dev  Recall    | 0.965762 | 0.82     | 0.872611 | 0.759563 | 0.478261 | 0.607143 | 0.646552 |       0.828496 |\n",
            "| test Precision | 0.966195 | 0.760369 | 0.871622 | 0.749271 | 0.622642 | 0.697143 | 0.75     |       0.844622 |\n",
            "| test Recall    | 0.973906 | 0.787589 | 0.868687 | 0.70411  | 0.622642 | 0.709302 | 0.6      |       0.844622 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 7: (hidden_size: 800, n_layers: 1, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.945736 | 0.55     | 0.713376 | 0.584699 | 0.347826 | 0.696429 | 0.525862 |       0.726375 |\n",
            "| dev  Recall    | 0.945736 | 0.55     | 0.713376 | 0.584699 | 0.347826 | 0.696429 | 0.525862 |       0.726375 |\n",
            "| test Precision | 0.948074 | 0.470046 | 0.685811 | 0.597668 | 0.301887 | 0.708571 | 0.58     |       0.712132 |\n",
            "| test Recall    | 0.956522 | 0.741818 | 0.725    | 0.756458 | 0.727273 | 0.409917 | 0.412811 |       0.712132 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 8: (hidden_size: 800, n_layers: 1, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.969961 | 0.715    | 0.834395 | 0.748634 | 0.478261 | 0.559524 | 0.525862 |       0.801389 |\n",
            "| dev  Recall    | 0.969961 | 0.715    | 0.834395 | 0.748634 | 0.478261 | 0.559524 | 0.525862 |       0.801389 |\n",
            "| test Precision | 0.965586 | 0.682028 | 0.804054 | 0.752187 | 0.528302 | 0.605714 | 0.625    |       0.822317 |\n",
            "| test Recall    | 0.959304 | 0.789333 | 0.85     | 0.6      | 0.571429 | 0.706667 | 0.628141 |       0.822317 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 9: (hidden_size: 800, n_layers: 2, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.941537 | 0.58     | 0.656051 | 0.622951 | 0.347826 | 0.654762 | 0.5      |       0.717913 |\n",
            "| dev  Recall    | 0.941537 | 0.58     | 0.656051 | 0.622951 | 0.347826 | 0.654762 | 0.5      |       0.717913 |\n",
            "| test Precision | 0.94183  | 0.534562 | 0.581081 | 0.626822 | 0.377358 | 0.688571 | 0.65     |       0.70927  |\n",
            "| test Recall    | 0.960851 | 0.700906 | 0.815166 | 0.707237 | 0.487805 | 0.396382 | 0.418006 |       0.70927  |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 10: (hidden_size: 800, n_layers: 2, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.968992 | 0.755    | 0.853503 | 0.775956 | 0.434783 | 0.64881  | 0.62931  |       0.823138 |\n",
            "| dev  Recall    | 0.968992 | 0.755    | 0.853503 | 0.775956 | 0.434783 | 0.64881  | 0.62931  |       0.823138 |\n",
            "| test Precision | 0.969545 | 0.714286 | 0.837838 | 0.822157 | 0.679245 | 0.714286 | 0.655    |       0.836884 |\n",
            "| test Recall    | 0.973399 | 0.824468 | 0.915129 | 0.65127  | 0.6      | 0.688705 | 0.658291 |       0.836884 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 11: (hidden_size: 800, n_layers: 3, directions: 1)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.92991  | 0.575    | 0.649682 | 0.63388  | 0.434783 | 0.696429 | 0.568965 |       0.683117 |\n",
            "| dev  Recall    | 0.92991  | 0.575    | 0.649682 | 0.63388  | 0.434783 | 0.696429 | 0.568965 |       0.683117 |\n",
            "| test Precision | 0.927973 | 0.550691 | 0.635135 | 0.632653 | 0.471698 | 0.734286 | 0.64     |       0.683971 |\n",
            "| test Recall    | 0.978327 | 0.640751 | 0.696296 | 0.611268 | 0.520833 | 0.395385 | 0.402516 |       0.683971 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n",
            "\u001b[1;11;11;11mModel 12: (hidden_size: 800, n_layers: 3, directions: 2)\u001b[0m\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "|                |        O |    B-PER |    I-PER |    B-LOC |    I-LOC |    B-ORG |    I-ORG |   All-Exapct-O |\n",
            "|----------------+----------+----------+----------+----------+----------+----------+----------+----------------|\n",
            "| dev  Precision | 0.980297 | 0.865    | 0.917197 | 0.73224  | 0.434783 | 0.494048 | 0.456897 |       0.817808 |\n",
            "| dev  Recall    | 0.980297 | 0.865    | 0.917197 | 0.73224  | 0.434783 | 0.494048 | 0.456897 |       0.817808 |\n",
            "| test Precision | 0.979595 | 0.813364 | 0.881757 | 0.717201 | 0.509434 | 0.588571 | 0.55     |       0.840084 |\n",
            "| test Recall    | 0.963457 | 0.743158 | 0.818182 | 0.743202 | 0.675    | 0.830645 | 0.718954 |       0.840084 |\n",
            "+----------------+----------+----------+----------+----------+----------+----------+----------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxaESRoco6bV"
      },
      "source": [
        "**Good luck!**"
      ]
    }
  ]
}